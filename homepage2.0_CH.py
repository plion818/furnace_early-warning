import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import plotly.graph_objs as go
import plotly.express as px # åŒ¯å…¥ Plotly Express
import requests # For API calls
import io # For converting DataFrame to in-memory CSV

# === é é¢åŸºç¤è¨­å®š (å¿…é ˆæ˜¯ç¬¬ä¸€å€‹ Streamlit æŒ‡ä»¤) ===
st.set_page_config(
    page_title="ğŸ”¥ åŠ ç†±çˆæ•¸æ“šè¶¨å‹¢åˆ†æå„€ (APIæ•´åˆç‰ˆ)",
    page_icon="ğŸ”¥",
    layout="wide"
)

# === API åŠè³‡æ–™è·¯å¾‘å¸¸æ•¸ ===
API_URL = "http://127.0.0.1:8000/detect_anomaly/"
RAW_DATA_PATH = "data/processed/sensorID_28_standardized.csv"

# === è¼‰å…¥ä¸»è¦æ„Ÿæ¸¬è³‡æ–™ ===
@st.cache_data # Cache the data loading to improve performance
def load_data():
    """
    å¾ RAW_DATA_PATH è¼‰å…¥æ„Ÿæ¸¬å™¨è³‡æ–™ã€‚
    å°‡ 'record Time' æ¬„ä½è½‰ç‚º datetime ç‰©ä»¶ã€‚
    å›å‚³:
        pd.DataFrame: åŒ…å«æ„Ÿæ¸¬è³‡æ–™çš„ DataFrameã€‚
    """
    try:
        df = pd.read_csv(RAW_DATA_PATH)
        df['record Time'] = pd.to_datetime(df['record Time'])
        # Ensure required columns for the API are present, even if not used directly by Streamlit visualization always
        # This is more of a check for data integrity for the API call.
        required_cols_for_api = ['resistance', 'resistance_scaled', 'record Time']
        if not all(col in df.columns for col in required_cols_for_api):
            missing = [col for col in required_cols_for_api if col not in df.columns]
            st.error(f"è³‡æ–™æª” {RAW_DATA_PATH} ç¼ºå°‘å¿…è¦æ¬„ä½: {missing}ã€‚API å‘¼å«å¯èƒ½æœƒå¤±æ•—ã€‚")
            # Depending on strictness, could return None or raise error
        return df
    except FileNotFoundError:
        st.error(f"éŒ¯èª¤ï¼šè³‡æ–™æª” {RAW_DATA_PATH} æœªæ‰¾åˆ°ã€‚è«‹ç¢ºèªæª”æ¡ˆè·¯å¾‘æ˜¯å¦æ­£ç¢ºã€‚")
        return None
    except Exception as e:
        st.error(f"è¼‰å…¥è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# --- API äº’å‹•å‡½å¼ ---
# Not caching this by default, as parameters might change or users might want fresh detection.
# If API calls are expensive and parameters are static for a view, @st.cache_data or @st.cache_resource could be used.
def fetch_anomalies_from_api(input_df):
    """
    ä½¿ç”¨æä¾›çš„ DataFrame å‘¼å«ç•°å¸¸åµæ¸¬ APIã€‚
    Args:
        input_df (pd.DataFrame): åŒ…å« 'resistance', 'resistance_scaled', 'record Time' æ¬„ä½çš„ DataFrameã€‚
    Returns:
        list: API å›å‚³çš„ç•°å¸¸é»åˆ—è¡¨ (å­—å…¸æ ¼å¼)ï¼Œæˆ–åœ¨éŒ¯èª¤æ™‚å›å‚³ Noneã€‚
    """
    if input_df is None or input_df.empty:
        st.warning("è¼¸å…¥ API çš„è³‡æ–™ç‚ºç©ºï¼Œè·³éåµæ¸¬ã€‚")
        return []

    st.info("â³ æ­£åœ¨é€é API åµæ¸¬ç•°å¸¸é»...")
    try:
        # å°‡ DataFrame è½‰æ›ç‚º CSV å­—ä¸²
        csv_data = input_df.to_csv(index=False)
        files = {'file': ('data.csv', csv_data.encode('utf-8'), 'text/csv')}

        # API åƒæ•¸ (å¯æ ¹æ“šéœ€æ±‚èª¿æ•´æˆ–å¾ UI ç²å–)
        api_params = {
            "window_size": 50,
            "z_thresh": 3.0,
            "stride": 1,
            "vote_threshold": 0.5
        }

        response = requests.post(API_URL, files=files, params=api_params, timeout=180) # Increased timeout
        response.raise_for_status()  # è‹¥ç‹€æ…‹ç¢¼ç‚º 4xx æˆ– 5xxï¼Œå‰‡æ‹‹å‡º HTTPError

        response_data = response.json()
        st.success(f"âœ… API ç•°å¸¸åµæ¸¬å®Œæˆï¼å…±å›å‚³ {len(response_data.get('anomalies', []))} å€‹æ½›åœ¨ç•°å¸¸é»ã€‚")
        return response_data.get('anomalies', []) # API å›å‚³çš„æ˜¯åŒ…å« 'anomalies' éµçš„å­—å…¸

    except requests.exceptions.Timeout:
        st.error("API è«‹æ±‚è¶…æ™‚ã€‚è«‹ç¨å¾Œå†è©¦æˆ–æª¢æŸ¥ä¼ºæœå™¨ç‹€æ…‹ã€‚")
        return None
    except requests.exceptions.ConnectionError:
        st.error(f"ç„¡æ³•é€£æ¥è‡³ API ({API_URL})ã€‚è«‹ç¢ºèª API æœå‹™æ˜¯å¦æ­£åœ¨é‹è¡Œã€‚")
        return None
    except requests.exceptions.HTTPError as e:
        st.error(f"API è«‹æ±‚å¤±æ•— (HTTP {e.response.status_code}): {e.response.text}")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"å‘¼å« API æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None
    except Exception as e: # Catch any other unexpected errors
        st.error(f"è™•ç† API å›æ‡‰æ™‚ç™¼ç”Ÿéé æœŸéŒ¯èª¤: {e}")
        return None


# --- è³‡æ–™è¼‰å…¥èˆ‡åˆå§‹åŒ– ---
df_global = load_data() # å…¨åŸŸ DataFrame

# åˆå§‹åŒ– session state
if 'time_start' not in st.session_state:
    st.session_state.time_start = datetime.strptime("2025-02-06 22:00:00", "%Y-%m-%d %H:%M:%S") if df_global is not None else datetime.now() - timedelta(hours=1)
    st.session_state.time_end = datetime.strptime("2025-02-06 23:00:00", "%Y-%m-%d %H:%M:%S") if df_global is not None else datetime.now()

if 'api_anomalies_data' not in st.session_state: # APIå›å‚³çš„åŸå§‹ç•°å¸¸è³‡æ–™
    st.session_state.api_anomalies_data = None
if 'processed_anomalies_df' not in st.session_state: # è™•ç†ä¸¦åˆä½µåˆ°ä¸»dfå¾Œçš„ç•°å¸¸è³‡æ–™ (çµ¦æ•´é«”çµ±è¨ˆç”¨)
    st.session_state.processed_anomalies_df = None


# === é é¢æ¨™é¡Œ ===
st.markdown("""
    <h1 style='text-align: center; color: #2C3E50;'>ğŸ“ˆ åŠ ç†±çˆæŒ‡æ¨™è¶¨å‹¢åˆ†æ (APIæ•´åˆ)</h1>
""", unsafe_allow_html=True)

# --- å´é‚Šæ¬„ UI ---
st.sidebar.markdown("---")

# API åµæ¸¬æŒ‰éˆ•
if st.sidebar.button("ğŸ”¥ åµæ¸¬é˜»æŠ—ç•°å¸¸é» (é€é API)"):
    if df_global is not None:
        api_result = fetch_anomalies_from_api(df_global.copy()) # Pass a copy to be safe
        if api_result is not None:
            st.session_state.api_anomalies_data = api_result
            # Process and merge for overall statistics
            anomalies_df = pd.DataFrame(st.session_state.api_anomalies_data)
            if not anomalies_df.empty:
                anomalies_df['record Time'] = pd.to_datetime(anomalies_df['record_Time']) # APIå›å‚³æ˜¯record_Time
                anomalies_df.rename(columns={'score': 'api_score', 'index': 'api_original_index'}, inplace=True)

                # Merge with a copy of the global df for overall stats
                df_for_stats = df_global.copy()
                df_for_stats = pd.merge(df_for_stats,
                                        anomalies_df[['record Time', 'api_score', 'api_original_index']],
                                        on='record Time',
                                        how='left')
                df_for_stats['is_api_anomaly'] = df_for_stats['api_score'].notna()
                st.session_state.processed_anomalies_df = df_for_stats
            else: # No anomalies returned from API
                df_for_stats = df_global.copy()
                df_for_stats['is_api_anomaly'] = False
                df_for_stats['api_score'] = np.nan
                st.session_state.processed_anomalies_df = df_for_stats

        else: # API call failed
            st.session_state.api_anomalies_data = None # Clear previous results on failure
            st.session_state.processed_anomalies_df = None
    else:
        st.sidebar.error("è³‡æ–™å°šæœªæˆåŠŸè¼‰å…¥ï¼Œç„¡æ³•é€²è¡Œ API åµæ¸¬ã€‚")


with st.sidebar.expander("â±ï¸ æ™‚é–“é¸æ“‡", expanded=True):
    st.markdown("### â± é¸æ“‡è³‡æ–™å€é–“")
    interval_minutes = st.selectbox("é¸æ“‡æ™‚é–“å€æ®µé•·åº¦", [15, 30, 60], index=1)

    manual_start = st.text_input("Start Time", st.session_state.time_start.strftime("%Y-%m-%d %H:%M:%S"))
    manual_end = st.text_input("End Time", st.session_state.time_end.strftime("%Y-%m-%d %H:%M:%S"))

    col_prev, col_next = st.columns(2)
    if col_prev.button("â¬… ä¸Šä¸€æ®µ"):
        delta = timedelta(minutes=interval_minutes)
        st.session_state.time_end = st.session_state.time_start
        st.session_state.time_start = st.session_state.time_end - delta
    if col_next.button("ä¸‹ä¸€æ®µ â¡"):
        delta = timedelta(minutes=interval_minutes)
        st.session_state.time_start = st.session_state.time_end
        st.session_state.time_end = st.session_state.time_start + delta

    if st.button("ğŸš€ ç”Ÿæˆåœ–è¡¨"):
        try:
            st.session_state.time_start = datetime.strptime(manual_start, "%Y-%m-%d %H:%M:%S")
            st.session_state.time_end = datetime.strptime(manual_end, "%Y-%m-%d %H:%M:%S")
        except ValueError:
            st.error("âŒ æ™‚é–“æ ¼å¼éŒ¯èª¤ï¼Œè«‹ä½¿ç”¨ YYYY-MM-DD HH:MM:SS")
            st.stop()

    st.markdown(f"**ç›®å‰æŸ¥è©¢å€é–“ï¼š**\n{st.session_state.time_start} ~ {st.session_state.time_end}")

st.sidebar.markdown("---")
with st.sidebar.expander("ğŸ“Š åœ–è¡¨é¸é …", expanded=True):
    columns = ['current', 'voltage', 'resistance', 'temperature']
    scaled_columns = ['current_scaled', 'voltage_scaled', 'resistance_scaled', 'temperature_scaled']
    mapping = dict(zip(columns, scaled_columns))

    selected_metrics = st.multiselect("é¸æ“‡è¦æ¯”è¼ƒçš„æ¨™æº–åŒ–æŒ‡æ¨™ (1~4)", columns, default=["resistance", "temperature"])
    st.markdown("---")
    raw_option = st.selectbox("é¸æ“‡è¦ç¹ªè£½çš„åŸå§‹æŒ‡æ¨™", ["none"] + columns, index=0)
    show_anomaly = st.checkbox("ğŸ” é¡¯ç¤ºé˜»æŠ—ç•°å¸¸é» (éœ€å…ˆé»æ“Šåµæ¸¬æŒ‰éˆ•)")


# --- æ ¹æ“šæ™‚é–“å€é–“éæ¿¾è³‡æ–™ ---
if df_global is None:
    st.warning("è³‡æ–™è¼‰å…¥å¤±æ•—ï¼Œç„¡æ³•é¡¯ç¤ºåœ–è¡¨ã€‚è«‹æª¢æŸ¥è³‡æ–™ä¾†æºã€‚")
    st.stop()

try:
    mask = (df_global['record Time'] >= st.session_state.time_start) & (df_global['record Time'] <= st.session_state.time_end)
    df_filtered = df_global.loc[mask].copy()
except Exception as e:
    st.error(f"âŒ æ™‚é–“æ ¼å¼è½‰æ›æˆ–è³‡æ–™éæ¿¾æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    st.stop()

# Initialize API anomaly columns in df_filtered
df_filtered['is_api_anomaly'] = False
df_filtered['api_score'] = np.nan
df_filtered['api_original_index'] = pd.NA # Using pandas NA for integer index if needed

# Merge API anomalies if available and checkbox is ticked
if show_anomaly and st.session_state.api_anomalies_data is not None:
    if st.session_state.api_anomalies_data: # Check if list is not empty
        anomalies_from_api_df = pd.DataFrame(st.session_state.api_anomalies_data)
        anomalies_from_api_df['record Time'] = pd.to_datetime(anomalies_from_api_df['record_Time'])
        anomalies_from_api_df.rename(columns={'score': 'api_score_temp', 'index': 'api_original_index_temp'}, inplace=True)

        # Merge with df_filtered
        df_filtered = pd.merge(
            df_filtered,
            anomalies_from_api_df[['record Time', 'api_score_temp', 'api_original_index_temp']],
            on='record Time',
            how='left'
        )
        # Update actual columns based on merged data
        df_filtered['is_api_anomaly'] = df_filtered['api_score_temp'].notna()
        df_filtered['api_score'] = df_filtered['api_score_temp']
        df_filtered['api_original_index'] = df_filtered['api_original_index_temp']
        # Drop temporary columns
        df_filtered.drop(columns=['api_score_temp', 'api_original_index_temp'], inplace=True)

        num_anomalies_interval = df_filtered['is_api_anomaly'].sum()
        total_interval = len(df_filtered)
        percentage_interval = (num_anomalies_interval / total_interval) * 100 if total_interval > 0 else 0
        st.info(f"ğŸ“Œ API åµæ¸¬ç•°å¸¸é»æ•¸é‡ï¼ˆç›®å‰å€é–“ï¼‰ï¼š{int(num_anomalies_interval)} / {total_interval} ç­†è³‡æ–™ï¼ˆ{percentage_interval:.2f}%ï¼‰")
    else: # API data is empty list
        st.info("API æœªå›å‚³ä»»ä½•ç•°å¸¸é»ã€‚")

st.success("âœ… åœ–è¡¨å·²ç”Ÿæˆã€‚è«‹æ»‘é¼ ç§»å‹•æª¢è¦–åŸå§‹è³‡æ–™è©³æƒ…")

# === æ¨™æº–åŒ–æ•¸æ“šè¶¨å‹¢åœ–ç¹ªè£½ ===
if selected_metrics:
    metric_colors = {
        'current': 'rgba(0, 0, 255, 0.8)', 'voltage': 'rgba(0, 128, 0, 0.8)',
        'resistance': 'rgba(255, 165, 0, 0.8)', 'temperature': 'rgba(128, 0, 128, 0.8)'
    }
    fig_scaled = go.Figure()
    for metric_name in selected_metrics:
        scaled_value_format = ".4f" if metric_name == 'resistance' else ".2f"
        hover_texts_metric = []
        for i in range(len(df_filtered)):
            row = df_filtered.iloc[i]
            current_metric_scaled_val = row[mapping[metric_name]]
            hover_text = (
                f"Time: {row['record Time'].strftime('%Y-%m-%d %H:%M:%S')}<br>"
                f"<b>{metric_name.capitalize()} (scaled): {current_metric_scaled_val:{scaled_value_format}}</b><br>"
                f"<b>----------- åŸå§‹æ•¸å€¼ ---------</b><br>"
                f"Current (raw): {row['current']:.2f} A<br>"
                f"Voltage (raw): {row['voltage']:.2f} V<br>"
                f"Resistance (raw): {row['resistance']:.4f} Î©<br>"
                f"Temperature (raw): {row['temperature']:.2f} Â°C"
            )
            if row['is_api_anomaly'] and pd.notna(row['api_score']):
                hover_text += f"<br><b style='color:red;'>API Anomaly Score: {row['api_score']:.4f}</b>"
            hover_texts_metric.append(hover_text)

        fig_scaled.add_trace(go.Scatter(
            x=df_filtered['record Time'], y=df_filtered[mapping[metric_name]], mode='lines+markers',
            name=f'{metric_name.capitalize()} (scaled)',
            marker=dict(size=5, color=metric_colors.get(metric_name, 'rgba(0,0,0,0.7)')),
            line=dict(color=metric_colors.get(metric_name, 'rgba(0,0,0,0.7)')),
            hoverinfo='text', text=hover_texts_metric, showlegend=True
        ))

    if 'resistance' in selected_metrics and show_anomaly and df_filtered['is_api_anomaly'].any():
        anomaly_points = df_filtered[df_filtered['is_api_anomaly'] == True]
        if not anomaly_points.empty:
            anomaly_hover_texts = []
            for i in range(len(anomaly_points)):
                row = anomaly_points.iloc[i]
                anomaly_hover_texts.append(
                    f"<span style='color:red'><b>åµæ¸¬åˆ°ç•°å¸¸ (Resistance via API)</b><br>"
                    f"Time: {row['record Time'].strftime('%Y-%m-%d %H:%M:%S')}<br>"
                    f"Resistance (scaled): {row['resistance_scaled']:.4f}<br>"
                    f"API Score: {row['api_score']:.4f}</span><br>"
                    f"<b>------------- åŸå§‹æ•¸å€¼ ------------</b><br>"
                    f"Current: {row['current']:.2f} A<br>"
                    f"Voltage: {row['voltage']:.2f} V<br>"
                    f"Resistance: {row['resistance']:.4f} Î©<br>"
                    f"Temperature: {row['temperature']:.2f} Â°C"
                )
            fig_scaled.add_trace(go.Scatter(
                x=anomaly_points['record Time'], y=anomaly_points['resistance_scaled'],
                mode='markers', name='Resistance Anomaly (API)',
                marker=dict(color='red', size=8, symbol='circle'),
                showlegend=True, hoverinfo='text', text=anomaly_hover_texts
            ))
    fig_scaled.update_layout(title='ğŸ“Š æ¨™æº–åŒ–æŒ‡æ¨™è¶¨å‹¢åœ–', xaxis_title='æ™‚é–“', yaxis_title='æ¨™æº–åŒ–æ•¸å€¼', hovermode='closest', height=500, margin=dict(l=40, r=40, t=60, b=40), legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1, bgcolor='rgba(255,255,255,0.5)'))
    st.plotly_chart(fig_scaled, use_container_width=True)

# === åŸå§‹æ•¸æ“šåœ–è¡¨ç¹ªè£½ ===
if raw_option != "none":
    if 'metric_colors' not in locals(): metric_colors = {'current': 'rgba(0,0,255,0.8)','voltage': 'rgba(0,128,0,0.8)','resistance': 'rgba(255,165,0,0.8)','temperature': 'rgba(128,0,128,0.8)'}
    raw_hover_texts = []
    for i in range(len(df_filtered)):
        row = df_filtered.iloc[i]
        raw_val = row[raw_option]
        raw_value_format = ".4f" if raw_option == 'resistance' else ".2f"
        hover_text = (
            f"Time: {row['record Time'].strftime('%Y-%m-%d %H:%M:%S')}<br>"
            f"<b>{raw_option.capitalize()}: {raw_val:{raw_value_format}}</b><br>"
            f"Current: {row['current']:.2f} A<br>"
            f"Voltage: {row['voltage']:.2f} V<br>"
            f"Resistance: {row['resistance']:.4f} Î©<br>"
            f"Temperature: {row['temperature']:.2f} Â°C"
        )
        if row['is_api_anomaly'] and pd.notna(row['api_score']):
             hover_text += f"<br><b style='color:red;'>API Anomaly Score: {row['api_score']:.4f}</b>"
        raw_hover_texts.append(hover_text)

    fig_raw = go.Figure()
    fig_raw.add_trace(go.Scatter(
        x=df_filtered['record Time'], y=df_filtered[raw_option], mode='lines+markers',
        name=f'{raw_option.capitalize()} (raw)',
        marker=dict(size=5, color=metric_colors.get(raw_option, 'rgba(0,0,0,0.7)')),
        line=dict(color=metric_colors.get(raw_option, 'rgba(0,0,0,0.7)')),
        hoverinfo='text', text=raw_hover_texts, showlegend=True
    ))

    if show_anomaly and raw_option == 'resistance' and df_filtered['is_api_anomaly'].any():
        anomaly_points = df_filtered[df_filtered['is_api_anomaly'] == True]
        if not anomaly_points.empty:
            raw_anomaly_hover_texts = []
            for i in range(len(anomaly_points)):
                row = anomaly_points.iloc[i]
                raw_anomaly_hover_texts.append(
                    f"<span style='color:red'><b>åµæ¸¬åˆ°ç•°å¸¸ (API)</b><br>"
                    f"Time: {row['record Time'].strftime('%Y-%m-%d %H:%M:%S')}<br>"
                    f"Resistance (raw): {row['resistance']:.4f} Î©<br>"
                    f"API Score: {row['api_score']:.4f}</span><br>"
                    f"<b>--------- åŸå§‹æ•¸å€¼ -------</b><br>"
                    f"Current: {row['current']:.2f} A<br>"
                    f"Voltage: {row['voltage']:.2f} V<br>"
                    f"Resistance: {row['resistance']:.4f} Î©<br>"
                    f"Temperature: {row['temperature']:.2f} Â°C"
                )
            fig_raw.add_trace(go.Scatter(
                x=anomaly_points['record Time'], y=anomaly_points['resistance'],
                mode='markers', name='Resistance Anomaly (API, raw)',
                marker=dict(color='red', size=8, symbol='circle'),
                showlegend=True, hoverinfo='text', text=raw_anomaly_hover_texts
            ))
    fig_raw.update_layout(title=f'ğŸ“ˆ åŸå§‹æŒ‡æ¨™è¶¨å‹¢åœ–: {raw_option.capitalize()}', xaxis_title='æ™‚é–“', yaxis_title='åŸå§‹æ•¸å€¼', hovermode='closest', height=500, margin=dict(l=40, r=40, t=60, b=40), legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1, bgcolor='rgba(255,255,255,0.5)'))
    st.plotly_chart(fig_raw, use_container_width=True)

# --- åŒ¯å‡ºç•°å¸¸è³‡æ–™æŒ‰éˆ• ---
if (selected_metrics or raw_option != "none") and show_anomaly and st.session_state.api_anomalies_data is not None and df_filtered['is_api_anomaly'].any():
    st.markdown("<div style='text-align: right;'>", unsafe_allow_html=True)
    # Prepare data for download: only rows that are API anomalies within the filtered view
    export_df = df_filtered[df_filtered['is_api_anomaly'] == True].copy()
    # Select relevant columns for export, could include original index from API if needed
    export_df = export_df[['record Time', 'current', 'voltage', 'resistance', 'temperature',
                           'current_scaled', 'voltage_scaled', 'resistance_scaled', 'temperature_scaled',
                           'api_score', 'api_original_index']] # Add more as needed

    csv_data_export = export_df.to_csv(index=False).encode('utf-8-sig')
    st.download_button(
        label="ğŸ“¤ åŒ¯å‡ºç›®å‰å€é–“ API åµæ¸¬ä¹‹ç•°å¸¸é»è³‡æ–™",
        data=csv_data_export,
        file_name="filtered_api_anomalies.csv",
        mime='text/csv',
        key="download-api-anomalies"
    )
    st.markdown("</div>", unsafe_allow_html=True)

# --- æ•´é«”ç•°å¸¸çµ±è¨ˆ (åŸºæ–¼ processed_anomalies_df from session state) ---
if show_anomaly and st.session_state.processed_anomalies_df is not None:
    st.markdown("---")
    df_stats_overall = st.session_state.processed_anomalies_df

    total_all_for_info = len(df_stats_overall)
    total_anomalies_for_info = df_stats_overall['is_api_anomaly'].sum()
    percent_all_for_info = (total_anomalies_for_info / total_all_for_info) * 100 if total_all_for_info > 0 else 0
    st.info(f"ğŸ“Š API åµæ¸¬ç•°å¸¸é»æ•¸é‡ï¼ˆå…¨éƒ¨è³‡æ–™ï¼‰ï¼š{int(total_anomalies_for_info)} / {total_all_for_info} ç­†è³‡æ–™ï¼ˆ{percent_all_for_info:.2f}%ï¼‰")

    st.markdown("---")
    st.subheader("ğŸ“Š API åµæ¸¬ä¹‹é›»é˜»ç•°å¸¸æ¯”ä¾‹ (æ•´é«”è³‡æ–™)")

    anomaly_count_chart = total_anomalies_for_info
    normal_count_chart = total_all_for_info - anomaly_count_chart
    normal_percentage = (normal_count_chart / total_all_for_info) * 100 if total_all_for_info > 0 else 0
    anomaly_percentage = (anomaly_count_chart / total_all_for_info) * 100 if total_all_for_info > 0 else 0

    chart_data_stacked = [
        {'Category': 'API é›»é˜»ç•°å¸¸åµæ¸¬', 'Segment': 'Normal', 'Count': normal_count_chart, 'Percentage': normal_percentage, 'TextOnBar': f"<b>{normal_percentage:.1f}%</b>"},
        {'Category': 'API é›»é˜»ç•°å¸¸åµæ¸¬', 'Segment': 'Anomaly', 'Count': anomaly_count_chart, 'Percentage': anomaly_percentage, 'TextOnBar': f"<b>{anomaly_percentage:.1f}%</b>"}
    ]
    df_chart_stacked = pd.DataFrame(chart_data_stacked)

    fig_stats = px.bar(
        df_chart_stacked, x='Count', y='Category', color='Segment', orientation='h', text='TextOnBar',
        custom_data=['Segment', 'Count', 'Percentage'],
        color_discrete_map={'Normal': 'rgba(0, 128, 0, 0.7)', 'Anomaly': 'rgba(255, 0, 0, 0.7)'}
    )
    fig_stats.update_layout(
        title_text="API é›»é˜»ç•°å¸¸åµæ¸¬ï¼šæ•´é«”è³‡æ–™çµ±è¨ˆ (Normal vs. Anomaly Proportions)",
        xaxis_title="ç¸½æ•¸é‡", yaxis_title=None, height=200, showlegend=True,
        legend_title_text='é¡å‹', legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
    )
    fig_stats.update_yaxes(visible=False, showticklabels=False)
    fig_stats.update_xaxes(range=[0, total_all_for_info])
    fig_stats.update_traces(
        textposition='inside', insidetextanchor='middle', textfont_size=15, textfont_color="black",
        hovertemplate=("<b>%{customdata[0]}</b><br><br>Count: %{customdata[1]}<br>Percentage: %{customdata[2]:.1f}%<extra></extra>")
    )
    st.plotly_chart(fig_stats, use_container_width=True)

else:
    if show_anomaly: # Checkbox is ticked but no data in session state yet
        st.warning("è«‹å…ˆé»æ“Šå´é‚Šæ¬„çš„ã€Œåµæ¸¬é˜»æŠ—ç•°å¸¸é» (é€é API)ã€æŒ‰éˆ•ä»¥è¼‰å…¥ä¸¦é¡¯ç¤º API åµæ¸¬çµæœã€‚")

st.sidebar.info("v1.1.0 - API æ•´åˆç‰ˆ")
